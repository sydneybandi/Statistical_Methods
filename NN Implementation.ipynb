{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "#to avoid dummy variable trap\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.T\n",
    "X_test=X_test.T\n",
    "y_train=y_train.reshape(y_train.shape[0],1)\n",
    "y_test=y_test.reshape(y_test.shape[0],1)\n",
    "y_train=y_train.T\n",
    "y_test=y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_X=X_train.shape\n",
    "shape_Y=y_train.shape\n",
    "m=X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (11, 8000)\n",
      "The shape of Y is: (1, 8000)\n",
      "I have m = 8000 training examples!\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of X is: ' + str(shape_X))\n",
    "print ('The shape of Y is: ' + str(shape_Y))\n",
    "print ('I have m = %d training examples!' % (m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_sizes(X,Y):\n",
    "    n_x=X.shape[0]\n",
    "    n_h=10\n",
    "    n_y=Y.shape[0]\n",
    "    return (n_x,n_h,n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n_x,n_h,n_y)=layer_sizes(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the input layer is: n_x = 11\n",
      "The size of the hidden layer is: n_h = 10\n",
      "The size of the output layer is: n_y = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of the input layer is: n_x = \" + str(n_x))\n",
    "print(\"The size of the hidden layer is: n_h = \" + str(n_h))\n",
    "print(\"The size of the output layer is: n_y = \" + str(n_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x,n_h,n_y):\n",
    "    W1=np.random.randn(n_h,n_x)*0.01\n",
    "    b1=np.zeros((n_h,1))\n",
    "    W2=np.random.randn(n_y,n_h)*0.01\n",
    "    b2=np.zeros((n_y,1))\n",
    "    parameters={\n",
    "            \"W1\":W1,\n",
    "            \"b1\":b1,\n",
    "            \"W2\":W2,\n",
    "            \"b2\":b2}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[-3.30237550e-03 -1.79864211e-03 -3.03942507e-03 -1.07481983e-02\n",
      "  -1.66605042e-02  8.20913677e-03  3.93521058e-03  1.50949194e-02\n",
      "  -9.53445729e-04 -4.67080468e-03 -2.05053949e-03]\n",
      " [ 9.74314607e-03 -1.92353978e-03 -1.15568746e-02  1.47297715e-02\n",
      "   1.68651217e-02  6.80462910e-04 -4.93480165e-03 -1.72267539e-03\n",
      "  -1.25561595e-03  8.76028226e-03 -3.65107625e-03]\n",
      " [-1.19600707e-03 -8.27143156e-03  9.02788743e-04 -2.90608236e-03\n",
      "  -1.17560478e-02  4.66743689e-03 -3.57860870e-03 -8.51703328e-03\n",
      "   1.32178187e-04 -2.13487757e-02 -3.85836581e-03]\n",
      " [ 5.92426653e-03 -2.79691761e-03 -3.23002787e-03 -7.23826466e-03\n",
      "   1.11349345e-03  7.61632276e-03 -9.77192533e-03  8.39441319e-03\n",
      "  -1.30036958e-02  5.85419759e-03  5.59226153e-03]\n",
      " [-3.90413442e-03  2.85901933e-03 -1.12031258e-02 -3.40081688e-03\n",
      "   7.19026436e-03 -4.48288946e-03  9.18705817e-03 -3.92568734e-03\n",
      "   1.05052332e-03  3.94336713e-03  1.09135724e-02]\n",
      " [-1.52625462e-03  4.65235976e-05  5.73989021e-03 -5.25163361e-03\n",
      "   1.10050072e-02 -1.40995754e-02 -2.81310714e-03 -3.25905192e-03\n",
      "  -8.37129886e-03 -1.59562619e-03  6.90643341e-03]\n",
      " [-9.27771464e-04 -3.09869149e-03  4.52750675e-03 -1.13924845e-02\n",
      "   1.17638328e-02 -1.56048953e-02 -1.30811915e-03 -1.28559975e-02\n",
      "   5.61511331e-03 -5.25270678e-03  2.32346701e-03]\n",
      " [-5.33850949e-03 -2.55902438e-03 -5.76997988e-03 -7.37165210e-03\n",
      "  -1.06488460e-02  4.95711735e-03  6.68906567e-03 -5.92041610e-03\n",
      "   3.90181966e-03 -2.61126512e-03  1.07648813e-02]\n",
      " [ 6.52760177e-03 -1.06394491e-02  1.00535514e-02  1.15990163e-02\n",
      "   1.02909025e-02  2.10319267e-02  1.19275844e-02  1.30357664e-02\n",
      "   1.09448431e-02  6.43032153e-04 -2.35947963e-02]\n",
      " [ 6.66114769e-03  6.24654904e-03  5.28070944e-03  9.75293008e-03\n",
      "   1.92736183e-02 -1.06283161e-02 -1.47654328e-03 -1.40687496e-02\n",
      "  -4.50898211e-03 -1.04513469e-02  5.40285236e-03]]\n",
      "b1 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W2 = [[-0.01506265 -0.01122512 -0.00661629 -0.00249629  0.01537054 -0.00875554\n",
      "  -0.00099835 -0.0083619  -0.00649788  0.00588275]]\n",
      "b2 = [[0.]]\n"
     ]
    }
   ],
   "source": [
    "parameters=initialize_parameters(n_x,n_h,n_y)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,parameters):\n",
    "    W1=parameters[\"W1\"]\n",
    "    b1=parameters[\"b1\"]\n",
    "    W2=parameters[\"W2\"]\n",
    "    b2=parameters[\"b2\"]\n",
    "    \n",
    "    Z1=np.dot(W1,X)+b1\n",
    "    A1=np.tanh(Z1)\n",
    "    Z2=np.dot(W2,A1)+b2\n",
    "    A2=1/(1+np.exp(-Z2))\n",
    "    \n",
    "    cache={\n",
    "            \"Z1\":Z1,\n",
    "            \"A1\":A1,\n",
    "            \"Z2\":Z2,\n",
    "            \"A2\":A2}\n",
    "    return A2,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2,cache=forward_propagation(X_train,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2,Y,parameters):\n",
    "    m=Y.shape[1]\n",
    "    logprobs=np.multiply(np.log(A2),Y)+np.multiply(np.log(1-A2),(1-Y))\n",
    "    cost=-(1/m)*np.sum(logprobs)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 0.6931222685429411\n"
     ]
    }
   ],
   "source": [
    "print(\"cost = \" + str(compute_cost(A2, y_train, parameters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters,cache,X,Y):\n",
    "    m=X.shape[1]\n",
    "    W1=parameters[\"W1\"]\n",
    "    b1=parameters[\"b1\"]\n",
    "    W2=parameters[\"W2\"]\n",
    "    b2=parameters[\"b2\"]\n",
    "    \n",
    "    A1=cache[\"A1\"]\n",
    "    A2=cache[\"A2\"]\n",
    "    \n",
    "    dZ2=A2-Y\n",
    "    dW2=(1/m)*np.dot(dZ2,A1.T)\n",
    "    db2=(1/m)*np.sum(dZ2,axis=1,keepdims=True)\n",
    "    dZ1 = np.multiply((np.dot(W2.T,dZ2)),(1-np.power(A1,2)))\n",
    "    dW1 = 1/(m)*np.dot(dZ1,X.T)\n",
    "    db1 = 1/(m)*np.sum(dZ1,axis=1,keepdims=True)\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW1 = [[ 1.06293870e-03 -2.63132247e-04 -1.73802297e-04 -6.44800549e-04\n",
      "   1.72374862e-03 -1.56763892e-04  7.16041103e-04 -3.24348388e-04\n",
      "  -7.48707391e-05 -9.14817037e-04  6.06241976e-05]\n",
      " [ 7.92132538e-04 -1.96087086e-04 -1.28997007e-04 -4.80638833e-04\n",
      "   1.28484384e-03 -1.17082544e-04  5.33778601e-04 -2.41278965e-04\n",
      "  -5.55817027e-05 -6.81849055e-04  4.54413528e-05]\n",
      " [ 4.66894964e-04 -1.15465431e-04 -7.63048545e-05 -2.82846566e-04\n",
      "   7.57390006e-04 -6.90944137e-05  3.14541454e-04 -1.42468448e-04\n",
      "  -3.28038777e-05 -4.02242105e-04  2.67255020e-05]\n",
      " [ 1.76168031e-04 -4.36066840e-05 -2.87989627e-05 -1.06754670e-04\n",
      "   2.85466986e-04 -2.60496830e-05  1.18736226e-04 -5.37806175e-05\n",
      "  -1.24870845e-05 -1.51699172e-04  1.00885392e-05]\n",
      " [-1.08506209e-03  2.68582133e-04  1.76787994e-04  6.57152316e-04\n",
      "  -1.75816899e-03  1.60398706e-04 -7.30757876e-04  3.30419770e-04\n",
      "   7.62374314e-05  9.34180840e-04 -6.15764376e-05]\n",
      " [ 6.18170366e-04 -1.53002820e-04 -1.01114770e-04 -3.74289726e-04\n",
      "   1.00159180e-03 -9.11195262e-05  4.16444851e-04 -1.88229367e-04\n",
      "  -4.33633787e-05 -5.31856589e-04  3.51287267e-05]\n",
      " [ 7.04620044e-05 -1.74151277e-05 -1.15295903e-05 -4.26449517e-05\n",
      "   1.14140159e-04 -1.03442938e-05  4.74513654e-05 -2.14433311e-05\n",
      "  -4.98368893e-06 -6.06118647e-05  4.02449989e-06]\n",
      " [ 5.90249367e-04 -1.46131155e-04 -9.64732436e-05 -3.57706671e-04\n",
      "   9.56822321e-04 -8.73054281e-05  3.97729010e-04 -1.80070122e-04\n",
      "  -4.14642621e-05 -5.08094245e-04  3.38515309e-05]\n",
      " [ 4.58365571e-04 -1.12992360e-04 -7.49807857e-05 -2.77636568e-04\n",
      "   7.42330418e-04 -6.80219542e-05  3.08683751e-04 -1.39982276e-04\n",
      "  -3.24180702e-05 -3.94164809e-04  2.65904074e-05]\n",
      " [-4.14856510e-04  1.02837045e-04  6.80270380e-05  2.51911455e-04\n",
      "  -6.72440489e-04  6.10448993e-05 -2.79397651e-04  1.26268953e-04\n",
      "   2.90863363e-05  3.56690429e-04 -2.34940676e-05]]\n",
      "db1 = [[-0.00445607]\n",
      " [-0.00332   ]\n",
      " [-0.00195681]\n",
      " [-0.0007385 ]\n",
      " [ 0.00454764]\n",
      " [-0.00259039]\n",
      " [-0.00029534]\n",
      " [-0.00247401]\n",
      " [-0.00192007]\n",
      " [ 0.00174008]]\n",
      "dW2 = [[ 1.55626405e-03 -1.40862621e-03 -7.46244086e-05  5.22581591e-05\n",
      "  -1.13889414e-03 -1.55865508e-03 -2.44678976e-03  5.92034065e-04\n",
      "  -1.08897707e-03 -3.10933149e-03]]\n",
      "db2 = [[0.296]]\n"
     ]
    }
   ],
   "source": [
    "grads = backward_propagation(parameters, cache, X_train, y_train)\n",
    "print (\"dW1 = \"+ str(grads[\"dW1\"]))\n",
    "print (\"db1 = \"+ str(grads[\"db1\"]))\n",
    "print (\"dW2 = \"+ str(grads[\"dW2\"]))\n",
    "print (\"db2 = \"+ str(grads[\"db2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate = 1.2):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    dW1 = grads[\"dW1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "    \n",
    "    W1 = W1-((learning_rate)*dW1)\n",
    "    b1 = b1-((learning_rate)*db1)\n",
    "    W2 = W2-((learning_rate)*dW2)\n",
    "    b2 = b2-((learning_rate)*db2)\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = update_parameters(parameters, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[-0.0045779  -0.00148288 -0.00283086 -0.00997444 -0.018729    0.00839725\n",
      "   0.00307596  0.01548414 -0.0008636  -0.00357302 -0.00212329]\n",
      " [ 0.00879259 -0.00168824 -0.01140208  0.01530654  0.01532331  0.00082096\n",
      "  -0.00557534 -0.00143314 -0.00118892  0.0095785  -0.00370561]\n",
      " [-0.00175628 -0.00813287  0.00099435 -0.00256667 -0.01266492  0.00475035\n",
      "  -0.00395606 -0.00834607  0.00017154 -0.02086609 -0.00389044]\n",
      " [ 0.00571286 -0.00274459 -0.00319547 -0.00711016  0.00077093  0.00764758\n",
      "  -0.00991441  0.00845895 -0.01298871  0.00603624  0.00558016]\n",
      " [-0.00260206  0.00253672 -0.01141527 -0.0041894   0.00930007 -0.00467537\n",
      "   0.01006397 -0.00432219  0.00095904  0.00282235  0.01098746]\n",
      " [-0.00226806  0.00023013  0.00586123 -0.00480249  0.0098031  -0.01399023\n",
      "  -0.00331284 -0.00303318 -0.00831926 -0.0009574   0.00686428]\n",
      " [-0.00101233 -0.00307779  0.00454134 -0.01134131  0.01162686 -0.01559248\n",
      "  -0.00136506 -0.01283027  0.00562109 -0.00517997  0.00231864]\n",
      " [-0.00604681 -0.00238367 -0.00565421 -0.0069424  -0.01179703  0.00506188\n",
      "   0.00621179 -0.00570433  0.00395158 -0.00200155  0.01072426]\n",
      " [ 0.00597756 -0.01050386  0.01014353  0.01193218  0.00940011  0.02111355\n",
      "   0.01155716  0.01320375  0.01098374  0.00111603 -0.0236267 ]\n",
      " [ 0.00715898  0.00612314  0.00519908  0.00945064  0.02008055 -0.01070157\n",
      "  -0.00114127 -0.01422027 -0.00454389 -0.01087938  0.00543105]]\n",
      "b1 = [[ 0.00534729]\n",
      " [ 0.003984  ]\n",
      " [ 0.00234817]\n",
      " [ 0.0008862 ]\n",
      " [-0.00545717]\n",
      " [ 0.00310847]\n",
      " [ 0.00035441]\n",
      " [ 0.00296881]\n",
      " [ 0.00230409]\n",
      " [-0.0020881 ]]\n",
      "W2 = [[-0.01693017 -0.00953477 -0.00652675 -0.002559    0.01673721 -0.00688515\n",
      "   0.0019378  -0.00907234 -0.00519111  0.00961395]]\n",
      "b2 = [[-0.3552]]\n"
     ]
    }
   ],
   "source": [
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n",
    "    np.random.seed(3)\n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[2]\n",
    "    \n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "         A2, cache = forward_propagation(X,parameters)\n",
    "         cost = compute_cost(A2,Y,parameters)\n",
    "         grads = backward_propagation(parameters,cache,X,Y)\n",
    "         parameters = update_parameters(parameters,grads,2)\n",
    "         \n",
    "         if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693124\n",
      "Cost after iteration 1000: 0.320580\n",
      "Cost after iteration 2000: 0.318327\n",
      "Cost after iteration 3000: 0.317805\n",
      "Cost after iteration 4000: 0.317461\n",
      "Cost after iteration 5000: 0.317252\n",
      "Cost after iteration 6000: 0.317112\n",
      "Cost after iteration 7000: 0.316962\n",
      "Cost after iteration 8000: 0.316740\n",
      "Cost after iteration 9000: 0.316186\n"
     ]
    }
   ],
   "source": [
    "parameters = nn_model(X_train, y_train, 10, num_iterations=10000, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "    A2, cache = forward_propagation(X,parameters)\n",
    "    predictions = (A2>0.5)*1\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions mean = 0.148\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(parameters, X_test)\n",
    "print(\"predictions mean = \" + str(np.mean(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test.T, y_pred.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1511,   84],\n",
       "       [ 193,  212]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c94d47e160>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD8CAYAAACrbmW5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFhlJREFUeJzt3XuUldV9xvHvMxcNEaOggtyMQMBIbILGENOYNMEoahLRpiaQqtTYNdpgqml1RUzqtVSrMXaZWM1o8JKkGK3VUK8FYjWpQUUlqAFlvDKAgOIlCgyCv/4xL+YEhpkz17Nn83xYe51z9rvP++53LdbDZr/7fY8iAjMzS0tVpTtgZmZbczibmSXI4WxmliCHs5lZghzOZmYJcjibmSXI4WxmliCHs5nZNkiaIWmVpCdL6s6TtEzSgqIcWbJtmqQGSU9LmlBSf3hR1yDprLKO7ZtQzMxaJumzwFvAjRGxX1F3HvBWRHx/i7ZjgJnAOGAwMAcYXWx+BjgUaAQeASZHxO9bO3ZN151Gy/rsNdnpb1tZ99L5le6CJWm0OruH9mTOupdmtnq8iHhA0t5l7m4icFNENAHPS2qgOagBGiLiOQBJNxVtWw1nT2uYmbXfqZIWFtMe/Yq6IcDSkjaNRd226lvlcDazrEhV7SiqkzS/pNSVcYirgJHAWGAFcNnmQ7fQNlqpb1W3T2uYmfWkKpUfaxFRD9S3Z/8RsXLze0nXAHcUHxuBYSVNhwLLi/fbqt8mj5zNLCvtGTl3bP8aVPLxGGDzSo5ZwCRJO0oaDowCHqb5AuAoScMl7QBMKtq2yiNnM8uK1OlriqX7mgl8DthdUiNwLvA5SWNpnpp4ATgZICKeknQzzRf6NgJTI2JTsZ9TgXuBamBGRDzV1rEdzmaWma6bEIiIyS1U/6SV9tOB6S3U3wXc1Z5jO5zNLCsdna5IjcPZzLLicDYzS1B7VmukLI+zMDMreORsZpYgh7OZWYLU4g15vY/D2cyy4pGzmVmCqqryiLU8zsLM7D0eOZuZJcfTGmZmCXI4m5klSJ7WMDNLj0fOZmYJqqqqrnQXuoTD2cyy4mkNM7MEeVrDzCxBDmczswR5WsPMLEHy7dtmZunpyh94rSSHs5llxdMaZmYJ8gVBM7MUeVrDzCxBeQycHc5mlpmqPNLZ4Wxmeckjmx3OZpaX8JyzmVmC8shmh7OZZaYqj3TOZHbGzKwglV/a3JVmSFol6cmSukslLZa0UNJtknYt6veWtE7SgqJcXfKdj0t6QlKDpCtUxm2MDmczy0u1yi9tux44fIu62cB+EfFR4BlgWsm2ZyNibFFOKam/CqgDRhVly31uxeFsZnnpwpFzRDwArNmi7n8iYmPxcR4wtPXuaBDwgYj4bUQEcCNwdFvHdjibWV7UjtJ53wDuLvk8XNLjku6X9JmibgjQWNKmsahrlS8Imlle2nFBUFIdzdMNm9VHRH2Z3/0usBH4eVG1AtgrIl6V9HHgdkkfoeV/BqKt/TuczSwv7RgRF0FcVhj/ySGkKcCXgEOKqQoiogloKt4/KulZYDTNI+XSqY+hwPK2juFpDTPLSlRXlV06QtLhwHeAoyJibUn9HpKqi/cjaL7w91xErAD+IOmgYpXGCcAv2zqOR85mlpcuXOYsaSbwOWB3SY3AuTSvztgRmF2siJtXrMz4LHCBpI3AJuCUiNh8MfHvaF750YfmOerSeeoWOZzNLC9dePt2RExuofon22h7K3DrNrbNB/Zrz7EdzmaWl0zuEHQ4m1le8shmh7OZZcZPpTMzS1B5t2Unz+FsZnnJZOTsdc6ddPWlJ/PiY1czf/Yl79V999tf4dmHr2Te3Rcx7+6LmPD5sQD037Uv99z0PVYvuo7LL/ibP9nPeWd+lSXzfsTqRdf1ZPeth11//e188Yvf5Etfmso//MOlNDVteG/bhRf+mP33P7aCvctEz96+3W0czp3001vuZ+IJF29V/8Nr7+KgI6Zx0BHTuPe+BQCsb3qHCy67hWnTf75V+7vmPMZnjvpet/fXKmflyle58cb/5tZbL+eOO65k06ZN3HnnAwA88cQS3nzzrQr3MA9RpbJLytqc1pD0YWAizQ/qCJpvO5wVEYu6uW+9wv89vJi9hu5eVtu165p48JGnGfHBgVtte/jxhq7umiVo06Z3Wb9+AzU1Naxf38SAAf3ZtGkTl1xyHZdddgZz5syrdBd7v+1hWkPSd4CbaP4PwMPAI8X7mZLO6v7u9V6nTJnAw/f+K1dfejK77rJTpbtjCRg4cDe+8Y1j+Pznv8HBB59A3747cfDBB/Czn93JIYeMY8CA/pXuYh62k2mNk4BPRMTFEfGzolwMjCu2WQuu+ekcxnzmND55+Fm8vOo1Lv7ecZXukiXgjTfeYu7ch5g791p+/esbWLduPbff/ivuuec3HHfclyvdvXxUV5VfEtZW794FBrdQP6jY1iJJdZLmS5q/8a3t77/rq155g3ffDSKCGTN/xYFjR1a6S5aABx9cwNChA+nffxdqa2s47LA/54orfs5LL63gsMPqGD/+JNata+LQQ+va3pltWyYj57bmnE8H5kpaAiwt6vYCPgScuq0vlT6Gr89ek9t8bmlu9hywKy+veh2AiRM+we+fXtrGN2x7MHjwHvzud4tZt24973vfjvz2t7/jxBOP5vjj/zhq3n//Y5k9u91PsLRSiV/oK1er4RwR90gaTfM0xhCa/61pBB6JiE090L/k3fDDb/GZT+3L7v12puGhH3HhD/6Tz35qDB8d80Ei4MXG1Xxr2rXvtV/8f1ew88592KG2hi9POJAvHXcRi5csY/rZX+drE/+c9/fZgYaHfsR1N93H9MtbfIaK9VIf+9g+TJjwaY455nRqaqrZd98RfO1rbf6UnLVXJuGs4jnR3WZ7HDlb29a9dH6lu2BJGt3pZB3xt7eUnTnPXXtssknuOwTNLC+JX+grl8PZzPKSybSGw9nM8pLHwNnhbGaZyeQOQYezmeXF0xpmZukJj5zNzBJU43A2M0uPR85mZgnynLOZWYLyyGaHs5nlJfVfOCmXw9nM8uJwNjNLULXD2cwsPV6tYWaWIE9rmJklKJNwzuT5TWZmzUIqu7RF0gxJqyQ9WVLXX9JsSUuK135FvSRdIalB0kJJB5R8Z0rRfomkKeWch8PZzPJSrfJL264HtvwtsbOAuRExCphbfAY4AhhVlDrgKmgOc+Bc4JM0/+TfuZsDvTUOZzPLS5XKL22IiAeANVtUTwRuKN7fABxdUn9jNJsH7CppEDABmB0RayLiNWA2Wwf+1qdR1smamfUW7QhnSXWS5peUujKOMDAiVgAUrwOK+iHA0pJ2jUXdtupb5QuCZpaXdlwPjIh6oL4bjxyt1LfKI2czy0pUqezSQSuL6QqK11VFfSMwrKTdUGB5K/WtcjibWV6k8kvHzAI2r7iYAvyypP6EYtXGQcAbxbTHvcBhkvoVFwIPK+pa5WkNM8tLF96+LWkm8Dlgd0mNNK+6uBi4WdJJwEvAsUXzu4AjgQZgLXAiQESskXQh8EjR7oKI2PIi41YczmaWlaounA+IiMnb2HRIC20DmLqN/cwAZrTn2A5nM8tKJo/WcDibWV4czmZmCVIm6exwNrOsdOWccyU5nM0sK3I4m5mlJ5NZDYezmeUlk8c5O5zNLC8eOZuZJcjhbGaWoCr/+raZWXo8cjYzS5DD2cwsQQ5nM7MEeSmdmVmCPHI2M0uQV2uYmSXII2czswQ5nM3MEuRwNjNLkFdrmJklqKq60j3oGg5nM8uKpzXMzBLk3xA0M0tQJtnscDazvDicy/TKc3/X3YewXuitdxor3QVLUN/a0Z3eh8PZzCxBNf71bTOz9FQpKt2FLuFwNrOs5HITSib/ATAza1bVjtIaSftIWlBS3pR0uqTzJC0rqT+y5DvTJDVIelrShM6ch0fOZpaVrprWiIingbEAkqqBZcBtwInA5RHx/dL2ksYAk4CPAIOBOZJGR8SmjhzfI2czy0qVyi/tcAjwbES82EqbicBNEdEUEc8DDcC4Dp9HR79oZpaiGpVfJNVJml9S6rax20nAzJLPp0paKGmGpH5F3RBgaUmbxqKuQxzOZpYVKcouEVEfEQeWlPqt96cdgKOAW4qqq4CRNE95rAAu29y0he50eI7Fc85mlpVuWK1xBPBYRKwE2PwKIOka4I7iYyMwrOR7Q4HlHT2oR85mlpWuWq1RYjIlUxqSBpVsOwZ4sng/C5gkaUdJw4FRwMMdPA2PnM0sL115E4qk9wOHAieXVF8iaSzNUxYvbN4WEU9Juhn4PbARmNrRlRrgcDazzNR04bRGRKwFdtui7vhW2k8HpnfFsR3OZpaVXO4QdDibWVb8bA0zswR55GxmlqBclqA5nM0sK57WMDNLkB+2b2aWoEyy2eFsZnnxtIaZWYK8WsPMLEGe1jAzS5BHzmZmCaqu8pyzmVlyPK1hZpYgr9YwM0uQ55zNzBLkcDYzS1CtpzXMzNLjkbOZWYIczmZmCap2OJuZpccjZzOzBHmds5lZgmo9cjYzS4+nNczMEuRpDTOzBHm1hplZgjytYWaWIP/6tplZgqozmXPO5N8YM7NmVe0obZH0gqQnJC2QNL+o6y9ptqQlxWu/ol6SrpDUIGmhpAM6ex5mZtmoUvmlTJ+PiLERcWDx+SxgbkSMAuYWnwGOAEYVpQ64qlPn0Zkvm5mlphvCeUsTgRuK9zcAR5fU3xjN5gG7ShrU4fPocPfMzBJUrSi7SKqTNL+k1G2xuwD+R9KjJdsGRsQKgOJ1QFE/BFha8t3Goq5DfEHQzLLSntUaEVEP1LfS5NMRsVzSAGC2pMWttG1pLN7hq5MeOZtZVrpyWiMilhevq4DbgHHAys3TFcXrqqJ5IzCs5OtDgeUdPo+OftHMLEXVKr+0RtJOknbe/B44DHgSmAVMKZpNAX5ZvJ8FnFCs2jgIeGPz9EdHeFrDzLLShc/WGAjcJgmas/I/IuIeSY8AN0s6CXgJOLZofxdwJNAArAVO7MzBHc5d6LzvXc+v719I//47c8svzwfgmcVLmX7Bz1i3tolBg3dj+iV/S9++fXhy4fP883k3AhABJ0/9MuO/0KllkZagl1es4Zyzb+DVV96kqkoc81cH8/XjxzP73kep//c7ef65l7lx5ncYs98HAZj34CJ++G+38c47m6itrea0f/xLxn3ywxU+i96lq6YDIuI54GMt1L8KHNJCfQBTu+jwqHl/3eftjQ/kcbtOGR6d/wzvf/+OnDNtxnvhfNxX/5lvn3ksH//EPtz+X79heeMrfPPvj2bduiZqa2uoqalm9erXmfSXF3DvfZdSU1Nd4bPoGREbK92FHrF69Ru8svoN9h2zF2+/vZ7jvnoRl11xCgJUJf7l/P/g9DO+8l44L160lN1225k9BuxKw5JlnHryD7nnVxdX9iR6UN/a8Z1+Msavlt9VduaMH3xksk/i8JxzF/r4gaPZZZed/qTuxRdWcsCBowE46FNjmDv7MQD69NnxvSDe0PQOSvaviHXGHnvswr5j9gJgp53ex/ARe7Jq5esMHzmIvYfvuVX7D+87jD0G7ArAyA8NZkPTRjZseKdH+9zb1VZF2SVlHQ5nSZ2aT9lejBw1hPvv+x0Ac+6dz8qX17y37YmFz/FXR53DV48+n7PPOW67GTVvr5Yve5XFi5ay30f3Lqv93NmPs8++Q9lhh9ru7VhmeuAmlB7RmZHz+dvaULqwe8Y1szpxiN7v3AuncPPM+/j6sRfy9tr11Nb+cZr/zz46gv+cdQE//cV3ue6au2lq8ggpV2vXrufMb/+YM75zLH379mmz/bMNy7niB7dx9jl/3QO9y0su4dzqBUFJC7e1ieYrmS0qXdi9Pc05t2T4iEH8+zXfBuDFF17mN/c/sVWbESMH0afPjjy7ZBlj9tu7h3to3e2ddzZx5un1HPHFcYw/dP822698+TXOOO3HXPAvf8OwvfbogR7mJZe52rZWawwEJgCvbVEv4MFu6VFm1rz6Jv13+wDvvvsu1/74Tr7ytb8AYFnjagbu2Z+ammqWL3+VF154mUFDdqtwb62rRQQXnvNTho/Yk+OmfKHN9n94cy2nffNKTj19ImMPGNkDPcxPLtdv2grnO4C+EbFgyw2S/rdbetSLTTujnkcfeYbXX3+Lw8efySlTj2Lt2iZunnkfAOO/cAATj/k0AI8/1sD1195NTU01VVVVTPunv6Zfv50r2X3rBgsef5Y7//shPjRqCJO/Mh2AqadNZMOGjVx60S94bc1bnPbNKxn94aFcWf/3/GLm/7J06Wquvfpurr36bgCurP8W/Xf7QCVPo1dJfbqiXF5KZxWxvSyls/bpiqV0j71yZ9mZc8DuX0w2yn0TipllRZn8EorD2cyykuxQuJ0czmaWle3lgqCZWa+SSTY7nM0sL209CrS3cDibWVY8rWFmlqBMstnhbGZ5cTibmSUolzsEHc5mlpVMstnhbGZ56cLfEKwoh7OZZcWrNczMErS9PM/ZzKxX8cjZzCxBmWSzw9nM8uKldGZmCXI4m5klKJNsdjibWV78SyhmZgnyyNnMLEG5LKXLZb22mRkA1e0orZE0TNJ9khZJekrSaUX9eZKWSVpQlCNLvjNNUoOkpyVN6Mx5eORsZlnpwpHzRuAfI+IxSTsDj0qaXWy7PCK+/6fH1RhgEvARYDAwR9LoiNjUkYN75GxmmVE7yrZFxIqIeKx4/wdgETCkla9MBG6KiKaIeB5oAMZ19CwczmaWFbXjT9n7lPYG9gceKqpOlbRQ0gxJ/Yq6IcDSkq810nqYt8rhbGZZkaraUVQnaX5Jqdt6f+oL3AqcHhFvAlcBI4GxwArgss1NW+hOh9f1ec7ZzDJT/og4IuqB+m3uSaqlOZh/HhH/VXxnZcn2a4A7io+NwLCSrw8FlpfdmS145GxmWRFVZZdW9yMJ+AmwKCJ+UFI/qKTZMcCTxftZwCRJO0oaDowCHu7oeXjkbGZZkbpszPlp4HjgCUkLirqzgcmSxtI8ZfECcDJARDwl6Wbg9zSv9Jja0ZUaAIro3lsd3974QB73UlqXithY6S5YgvrWju/0Qrg335lTduZ8oPYLyd6y4pGzmWWlPaswUuZwNrOsOJzNzBIktXVjdu/gcDazzHjkbGaWHE9rmJklKY/bNxzOZpYVj5zNzBKkTJ6273A2s6yozcfo9w4OZzPLjEfOZmbJ8bSGmVmSHM5mZslp61GgvYXD2cwy45GzmVlyqrruec4V5XA2s8w4nM3MkuM7BM3MkuRwNjNLjtc5m5klKJfbt7v9B17tjyTVRUR9pfthafHfC2tJHpc1e4+6SnfAkuS/F7YVh7OZWYIczmZmCXI49yzPK1pL/PfCtuILgmZmCfLI2cwsQQ7nHiLpcElPS2qQdFal+2OVJ2mGpFWSnqx0Xyw9DuceIKkauBI4AhgDTJY0prK9sgRcDxxe6U5YmhzOPWMc0BARz0XEBuAmYGKF+2QVFhEPAGsq3Q9Lk8O5ZwwBlpZ8bizqzMxa5HDuGS09icXLZMxsmxzOPaMRGFbyeSiwvEJ9MbNewOHcMx4BRkkaLmkHYBIwq8J9MrOEOZx7QERsBE4F7gUWATdHxFOV7ZVVmqSZwG+BfSQ1Sjqp0n2ydPgOQTOzBHnkbGaWIIezmVmCHM5mZglyOJuZJcjhbGaWIIezmVmCHM5mZglyOJuZJej/AfkLzhnvEV1tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=100*(cm[0][0]+cm[1][1])/X_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.15%\n"
     ]
    }
   ],
   "source": [
    "print(str(accuracy)+ \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
